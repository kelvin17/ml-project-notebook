{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kelvin17/ml-project-notebook/blob/main/Yanqing_Project_1_hotdog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_IKiLxIQbA0"
      },
      "source": [
        "## 0. Exercise 1.4 Hotdog -- no hotdog\n",
        "This is the poster hand-in project for the course. Please see the associated PDF for instructions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRIhx7PugJy3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import glob\n",
        "import PIL.Image as Image\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## todo check\n",
        "from torchvision import transforms, datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35PhqXpWUZ7I"
      },
      "source": [
        "We always check that we are running on a GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ic_gOv_pUZeB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    print(\"The code will run on GPU.\")\n",
        "else:\n",
        "    print(\"The code will run on CPU. Go to Edit->Notebook Settings and choose GPU as the hardware accelerator\")\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAj64PJYgJzC"
      },
      "source": [
        "We provide you with a class that can load the *hotdog/not hotdog* dataset you should use from /dtu/datasets1/02516/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwzESiMITtvi"
      },
      "outputs": [],
      "source": [
        "class Hotdog_NotHotdog(torch.utils.data.Dataset):\n",
        "    def __init__(self, train, transform, data_path='/dtu/datasets1/02516/hotdog_nothotdog'):\n",
        "        'Initialization'\n",
        "        self.transform = transform\n",
        "        data_path = os.path.join(data_path, 'train' if train else 'test')\n",
        "        image_classes = [os.path.split(d)[1] for d in glob.glob(data_path +'/*') if os.path.isdir(d)]\n",
        "        image_classes.sort()\n",
        "        self.name_to_label = {c: id for id, c in enumerate(image_classes)} # result: {\"hotdog:0, nonhotdog:1\"}; enumerate(image_classes) result is (0,'hotdog'), (1,'nothotdog')\n",
        "        self.image_paths = glob.glob(data_path + '/*/*.jpg') # result is a list containing all the image-path \".../train/hotdog/img1.jpg\"\n",
        "\n",
        "    def __len__(self):\n",
        "        'Returns the total number of samples'\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        'Generates one sample of data'\n",
        "        image_path = self.image_paths[idx]\n",
        "\n",
        "        image = Image.open(image_path) # Image lib open the image\n",
        "        c = os.path.split(os.path.split(image_path)[0])[1]\n",
        "        # os.path.split 专门用来拆最后一个分隔符的。[0] 是最后一个分隔符前半段；[1]是后半段\n",
        "        # image_path = \".../train/hotdog/img1.jpg\"\n",
        "        #     内部取前半段：                             os.path.split(image_path)[0] => .../train/hotdog\n",
        "        #     外部取内部再次分隔的后半段：   os.path.split(os.path.split(image_path)[0])[1]  => hotdog\n",
        "\n",
        "        y = self.name_to_label[c]\n",
        "        X = self.transform(image)\n",
        "        return X, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JewkmhKlgJzN"
      },
      "source": [
        "Below is the simple way of converting the images to something that can be fed through a network.\n",
        "Feel free to use something other than $128\\times128$ images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Aal5yyDUPAA"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_path = '/content/drive/MyDrive/hotdog_nothotdog/'\n",
        "model_save_path = '/content/drive/MyDrive/model_output/hotdog_nothotdog/'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcilkL3dgJzP"
      },
      "outputs": [],
      "source": [
        "size = 128\n",
        "train_transform = transforms.Compose([transforms.Resize((size, size)),\n",
        "                                    transforms.ToTensor()])\n",
        "test_transform = transforms.Compose([transforms.Resize((size, size)),\n",
        "                                    transforms.ToTensor()])\n",
        "\n",
        "batch_size = 64\n",
        "trainset = Hotdog_NotHotdog(train=True, transform=train_transform, data_path=data_path)\n",
        "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=3)\n",
        "testset = Hotdog_NotHotdog(train=False, transform=test_transform, data_path=data_path)\n",
        "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZuITSLE8Y1bp"
      },
      "outputs": [],
      "source": [
        "num_test_images = len(test_loader.dataset)\n",
        "print(f'Test set has {num_test_images} images')\n",
        "\n",
        "num_train_images = len(train_loader.dataset)\n",
        "print(f'Train set has {num_train_images} images')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ho-YRb6HgJzZ"
      },
      "source": [
        "Let's look at some images from our data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNajHUpP4Cnn"
      },
      "outputs": [],
      "source": [
        "# images, labels = next(iter(train_loader))\n",
        "# print(images.shape)\n",
        "# print(labels.shape)\n",
        "\n",
        "for images, labels in train_loader:\n",
        "  print(type(images))\n",
        "  print(images.dtype)\n",
        "  print(images.shape)\n",
        "  print(images.size())\n",
        "  # print(images)\n",
        "  print(type(labels))\n",
        "  print(labels.dtype)\n",
        "  print(labels.shape)\n",
        "  print(labels.size())\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Sm4Ara7dgJza"
      },
      "outputs": [],
      "source": [
        "# images, labels = next(iter(train_loader))\n",
        "plt.figure(figsize=(20,10)) # create a huge figure\n",
        "\n",
        "for i in range(21):\n",
        "    plt.subplot(5,7,i+1) # create 5row*7column subplot. the index of location is i+1\n",
        "    plt.imshow(np.swapaxes(np.swapaxes(images[i].numpy(), 0, 2), 0, 1)) # swap axes : PyTorch.image [C,H,W] plt need [H,W,C]. so we need to do swap\n",
        "    plt.title(['hotdog', 'not hotdog'][labels[i].item()])\n",
        "    plt.axis('off')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12N0EYYsQPhJ"
      },
      "source": [
        "Now create a model and train it!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Lfqguohe0AU"
      },
      "source": [
        "# 1. function def"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lyHT1v_pezKc"
      },
      "outputs": [],
      "source": [
        "## 1. calculate accuracy and loss\n",
        "def evaluate(model, loader, device, loss_func):\n",
        "  model.eval()\n",
        "  running_loss = 0.0\n",
        "  correct, total = 0,0\n",
        "  with torch.no_grad():\n",
        "    for imgs, labels in loader:\n",
        "      imgs, labels = imgs.to(device), labels.to(device)\n",
        "      outputs = model(imgs)\n",
        "      loss = loss_func(outputs, labels) # return 0-dim tensor; .item() will return a scale\n",
        "      running_loss += loss.item() * imgs.size(0)\n",
        "      pred = outputs.argmax(1)\n",
        "      correct += (pred == labels).sum().item()\n",
        "      total += labels.size(0)\n",
        "  return 100 * correct / total, running_loss / total\n",
        "\n",
        "## 3. show some figures of the result\n",
        "def show_result(model, loader, classes, device):\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    data_iter = iter(loader)\n",
        "    images, labels = next(data_iter)\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(images)\n",
        "        probs = F.softmax(outputs, dim=1)\n",
        "        _, pred = torch.max(outputs, 1)\n",
        "\n",
        "    fig = plt.figure(figsize=(15, 5))\n",
        "\n",
        "    for i in range(10):\n",
        "      ax = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[])\n",
        "      # because the image may be on GPU\n",
        "      ax.imshow(images[i].permute(1, 2, 0).cpu().numpy())\n",
        "      pred_class = classes[pred[i]]\n",
        "      true_class = classes[labels[i]]\n",
        "      pred_prob = probs[i][pred[i]].item()*100\n",
        "\n",
        "      color = 'green' if pred_class == true_class else 'red'\n",
        "\n",
        "      ax.set_title(f\"Predicted: {pred_class}\\nActual: {true_class}\\n prob: {pred_prob:.1f}%\", fontsize=10, color=color)\n",
        "      ax.axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def show_result_random(model, loader, classes, device, num_images=10):\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "    import torch.nn.functional as F\n",
        "    import torch\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # 随机选择一个 batch\n",
        "    data_iter = iter(loader)\n",
        "    images, labels = next(data_iter)\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    batch_size = images.size(0)\n",
        "    num_images = min(num_images, batch_size)  # 防止 batch 小于 10\n",
        "\n",
        "    # 从 batch 中随机选择 num_images 张\n",
        "    random_indices = np.random.choice(batch_size, num_images, replace=False)\n",
        "    images = images[random_indices]\n",
        "    labels = labels[random_indices]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(images)\n",
        "        probs = F.softmax(outputs, dim=1)\n",
        "        _, pred = torch.max(outputs, 1)\n",
        "\n",
        "    fig = plt.figure(figsize=(15, 5))\n",
        "\n",
        "    for i in range(num_images):\n",
        "        ax = fig.add_subplot(2, (num_images + 1) // 2, i+1, xticks=[], yticks=[])\n",
        "        ax.imshow(images[i].permute(1, 2, 0).cpu().numpy())\n",
        "        pred_class = classes[pred[i]]\n",
        "        true_class = classes[labels[i]]\n",
        "        pred_prob = probs[i][pred[i]].item()*100\n",
        "\n",
        "        color = 'green' if pred_class == true_class else 'red'\n",
        "        ax.set_title(f\"Predicted: {pred_class}\\nActual: {true_class}\\nprob: {pred_prob:.1f}%\", fontsize=10, color=color)\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYqyc3bjyI5D"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=10, delta=0.0, mode=\"min\", path=\"checkpoint.pt\"):\n",
        "        \"\"\"\n",
        "        patience: how many epoch the metric no improved will stop\n",
        "        delta: the mini improved threadhold\n",
        "        mode: min or max - min: the lower the better, e.g the loss; max: the higher the better, e.g the accuracy or the AUC\n",
        "        path: where to save the model\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.delta = delta\n",
        "        self.mode = mode\n",
        "        self.path = path\n",
        "        self.best_score = None\n",
        "        self.counter = 0\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, metric, model):\n",
        "        score = -metric if self.mode == \"min\" else metric\n",
        "        if self.best_score is None:\n",
        "          self.best_score = score\n",
        "          self.save_checkpoint(model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "          self.counter += 1\n",
        "          if self.counter >= self.patience:\n",
        "            self.early_stop = True\n",
        "            print(f\"Early stopping, The best score is {self.best_score}\")\n",
        "        else:\n",
        "          self.best_score = score\n",
        "          self.save_checkpoint(model)\n",
        "          self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, model):\n",
        "        torch.save(model.state_dict(), self.path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNXVBS6vw-Xl"
      },
      "outputs": [],
      "source": [
        "def plot_curve(train_losses, train_accs, test_losses, test_accs, total_epochs, plt_path = None):\n",
        "    plt.figure(figsize=(12,5))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(range(1,total_epochs+1), train_losses, label='Train Loss')\n",
        "    plt.plot(range(1,total_epochs+1), test_losses, label='Val Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.title('Loss Curve')\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(range(1,total_epochs+1), train_accs, label='Train Acc')\n",
        "    plt.plot(range(1,total_epochs+1), test_accs, label='Val Acc')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.title('Accuracy Curve')\n",
        "\n",
        "    if plt_path is not None:\n",
        "        plt.savefig(plt_path, dpi=300, bbox_inches='tight')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def train(model, epochs_num, train_loader, val_loader, device, optimizer, loss_fc, scheduler = None, early_stopping = None, is_plot_curve = False, model_path = None, plt_path=None):\n",
        "    train_losses, train_accs = [], []\n",
        "    val_losses, val_accs = [], []\n",
        "    for epoch in range(epochs_num):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        start = time.time()\n",
        "\n",
        "        for imgs, labels in train_loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad() # location: must be by followed by backward. recommand to the begining of every loop\n",
        "            outputs = model(imgs)\n",
        "\n",
        "            loss = loss_fc(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * imgs.size(0)\n",
        "            _, pred = outputs.max(1)\n",
        "            correct += (pred == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "        train_loss = running_loss / len(trainset)\n",
        "        train_acc = correct / total * 100\n",
        "        train_losses.append(train_loss)\n",
        "        train_accs.append(train_acc)\n",
        "\n",
        "        val_acc, val_loss = evaluate(model, val_loader, device, loss_fc)\n",
        "        val_losses.append(val_loss)\n",
        "        val_accs.append(val_acc)\n",
        "\n",
        "        if scheduler is not None:\n",
        "           scheduler.step()\n",
        "\n",
        "        elapsed = time.time() - start\n",
        "        print(f\"Epoch {epoch}/{epochs_num}, Train Loss: {train_loss:.4f},Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%, train_acc: {train_acc:.2f}%, Time: {elapsed:.2f}s\")\n",
        "\n",
        "        total_runned_epochs = epoch+1\n",
        "\n",
        "        if early_stopping is not None:\n",
        "           early_stopping(val_acc, model)\n",
        "           if early_stopping.early_stop:\n",
        "              break\n",
        "        else:\n",
        "           if (total_runned_epochs == epochs_num) and (model_path is not None):\n",
        "              torch.save(model.state_dict(), model_path)\n",
        "\n",
        "    if is_plot_curve:\n",
        "       plot_curve(train_losses, train_accs, val_losses, val_accs, total_runned_epochs, plt_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjDZdOfqflP5"
      },
      "source": [
        "# 2. Training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdsZOpMkfpWT"
      },
      "source": [
        "## 2.1 Small CNN\n",
        "Performance - 80.5%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZHQ9rYO3IdU"
      },
      "outputs": [],
      "source": [
        "## small CNN\n",
        "class SmallCNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SmallCNN, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1) # keep the size\n",
        "    self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1) # keep the size\n",
        "    self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1) # keep the size\n",
        "    self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1) # keep the size\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.fc1 = nn.Linear(256 * 8 * 8, 128)\n",
        "    self.fc2 = nn.Linear(128, 2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = self.pool(F.relu(self.conv3(x)))\n",
        "    x = self.pool(F.relu(self.conv4(x)))\n",
        "    x = x.view(-1, 256 * 8 * 8)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McYe2kC87qwS"
      },
      "outputs": [],
      "source": [
        "# size = 128\n",
        "batch_size = 64\n",
        "epochs_num = 50\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(128, scale=(0.6, 1.0)),\n",
        "    transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((128,128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "trainset = Hotdog_NotHotdog(train=True, transform=transform_train, data_path=data_path)\n",
        "\n",
        "val_ratio = 0.2\n",
        "total_size = len(trainset)\n",
        "val_size = int(total_size * val_ratio)\n",
        "train_size = total_size - val_size\n",
        "\n",
        "trainset, valset = random_split(trainset, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=3)\n",
        "val_loader = DataLoader(valset, batch_size=batch_size, shuffle=True, num_workers=3)\n",
        "\n",
        "testset = Hotdog_NotHotdog(train=False, transform=transform_test, data_path=data_path)\n",
        "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8Pz_KQ58f7-"
      },
      "outputs": [],
      "source": [
        "# training processing\n",
        "model = SmallCNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=3e-4)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
        "\n",
        "model_path = model_save_path+'/best_small_model.pth'\n",
        "early_stopping = EarlyStopping(patience=10, mode=\"max\", path=model_path)\n",
        "plt_path = model_save_path+'/small_model.png'\n",
        "\n",
        "train(model, epochs_num, train_loader, val_loader, device, optimizer, criterion, scheduler, early_stopping, is_plot_curve = True, plt_path=plt_path)\n",
        "\n",
        "# Evaluation on Test\n",
        "best_model = SmallCNN()\n",
        "best_model.load_state_dict(torch.load(model_path))\n",
        "best_model.to(device)\n",
        "\n",
        "test_acc, _ = evaluate(best_model, test_loader, device, criterion)\n",
        "print(f\"Test Accuracy: {test_acc:.2f}%, according model saved to {model_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-znhavn8jdR"
      },
      "outputs": [],
      "source": [
        "classes = list(testset.name_to_label.keys())\n",
        "show_result(model, test_loader, classes, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pITKeJC1fx0Y"
      },
      "source": [
        "## 2.2 Optimized Small CNN\n",
        "Performance - 81.63%\n",
        "1. Optimized Model layer\n",
        "  - using batch normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "crLAKYpdMl4Y"
      },
      "outputs": [],
      "source": [
        "## 2. Improved CNN model\n",
        "batch_size = 64\n",
        "epochs_num = 50\n",
        "\n",
        "# -------------------------------\n",
        "# imporved small CNN Definition\n",
        "# -------------------------------\n",
        "class OptimizedSmallCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(OptimizedSmallCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32, momentum=0.01)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64, momentum=0.01)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128, momentum=0.01)\n",
        "        self.conv4 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(256, momentum=0.01)\n",
        "        self.pool = nn.MaxPool2d(2,2)\n",
        "        self.fc1 = nn.Linear(256*8*8, 128)\n",
        "        self.fc2 = nn.Linear(128, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
        "        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n",
        "        x = x.view(-1, 256*8*8)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        # x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# -------------------------------\n",
        "# Augmentation and Normalize\n",
        "# -------------------------------\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(128, scale=(0.6, 1.0)),\n",
        "    transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((128,128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128,128)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "trainset = Hotdog_NotHotdog(train=True, transform=transform_train, data_path=data_path)\n",
        "# trainset = Hotdog_NotHotdog(train=True, transform=transform, data_path=data_path)\n",
        "\n",
        "val_ratio = 0.2\n",
        "total_size = len(trainset)\n",
        "val_size = int(total_size * val_ratio)\n",
        "train_size = total_size - val_size\n",
        "\n",
        "\n",
        "trainset, valset = random_split(trainset, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=3)\n",
        "val_loader = DataLoader(valset, batch_size=batch_size, shuffle=True, num_workers=3)\n",
        "\n",
        "testset = Hotdog_NotHotdog(train=False, transform=transform_test, data_path=data_path)\n",
        "# testset = Hotdog_NotHotdog(train=False, transform=transform, data_path=data_path)\n",
        "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=3)\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# instantiate loss function, optimizer and learn rate scheduler\n",
        "# -------------------------------\n",
        "model = OptimizedSmallCNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=3e-4)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
        "\n",
        "# -------------------------------\n",
        "# training loop\n",
        "# -------------------------------\n",
        "model_path = model_save_path+'/best_optimized_model.pth'\n",
        "early_stopping = EarlyStopping(patience=10, mode=\"max\", path=model_path)\n",
        "plt_path = model_save_path+'/optimized_model.png'\n",
        "\n",
        "train(model, epochs_num, train_loader, val_loader, device, optimizer, criterion, scheduler, early_stopping, is_plot_curve = True, plt_path=plt_path)\n",
        "\n",
        "# Evaluation on Test\n",
        "best_model = OptimizedSmallCNN()\n",
        "best_model.load_state_dict(torch.load(model_path))\n",
        "best_model.to(device)\n",
        "\n",
        "test_acc, _ = evaluate(best_model, test_loader, device, criterion)\n",
        "print(f\"Test Accuracy: {test_acc:.2f}%, according model saved to {model_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhPXkjcpBCJX"
      },
      "outputs": [],
      "source": [
        "classes = list(testset.name_to_label.keys())\n",
        "show_result(model, test_loader, classes, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnXU2hEKf2-d"
      },
      "source": [
        "## 2.3 Transfer learning on resNet18\n",
        "Performence - 92.64% on test\n",
        "1. Fine tune resNet18(layer4+new fc for 2-classes)\n",
        "2. Data Augmentation\n",
        "3. scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "4. save the best test-accuracry parameters\n",
        "5. loss and accuracy curve of training and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_lT2dNn0ZQMf"
      },
      "outputs": [],
      "source": [
        "epochs_num = 50\n",
        "batch_size = 64\n",
        "tune_block4 = True\n",
        "# -------------------------------\n",
        "# 1. Load pre-trained model and setting fine tune\n",
        "# -------------------------------\n",
        "# 1.1 load pre-trained model\n",
        "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "\n",
        "# 1.2 keep all the parameters except the last layer's\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "# 1.3 replace the last fc layer for 2-classifier\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 2) # new 2-class fc ; default model.fc.requires_grad = True\n",
        "\n",
        "# 1.4 set fine tune - layer4\n",
        "if tune_block4:\n",
        "  for name, param in model.named_parameters():\n",
        "      if name.startswith(\"layer4\"):\n",
        "          param.requires_grad = True\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Augmentation and Normalize\n",
        "# -------------------------------\n",
        "transform_train = transform_train = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(128, scale=(0.6, 1.0)),\n",
        "    transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    transforms.RandomErasing(p=0.5)\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((128,128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "\n",
        "trainset = Hotdog_NotHotdog(train=True, transform=transform_train, data_path=data_path)\n",
        "\n",
        "val_ratio = 0.2\n",
        "total_size = len(trainset)\n",
        "val_size = int(total_size * val_ratio)\n",
        "train_size = total_size - val_size\n",
        "\n",
        "trainset, valset = random_split(trainset, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=3)\n",
        "val_loader = DataLoader(valset, batch_size=batch_size, shuffle=True, num_workers=3)\n",
        "\n",
        "testset = Hotdog_NotHotdog(train=False, transform=transform_test, data_path=data_path)\n",
        "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "j8ohB6kYjeC5"
      },
      "outputs": [],
      "source": [
        "# -------------------------------\n",
        "# 3. Loss function & Optimizer for fine tune & learning scheduler\n",
        "# -------------------------------\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "if tune_block4:\n",
        "  optimizer = optim.AdamW([\n",
        "      {'params': model.layer4.parameters(), 'lr': 1e-4},\n",
        "      {'params': model.fc.parameters(), 'lr': 3e-4}\n",
        "  ], weight_decay=1e-4)\n",
        "else:\n",
        "  optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=3e-4, weight_decay=1e-4)\n",
        "\n",
        "\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Train loop\n",
        "# -------------------------------\n",
        "if tune_block4:\n",
        "  model_path = model_save_path+'/best_resnet18_model-b4-fc.pth'\n",
        "  plt_path = model_save_path+'/resnet18_model-b4-fc.png'\n",
        "else:\n",
        "  model_path = model_save_path+'/best_resnet18_model-fc.pth'\n",
        "  plt_path = model_save_path+'/resnet18_model-fc.png'\n",
        "\n",
        "early_stopping = EarlyStopping(patience=10, mode=\"max\", path=model_path)\n",
        "\n",
        "train(model, epochs_num, train_loader, val_loader, device, optimizer, criterion, scheduler, early_stopping, is_plot_curve = True, plt_path=plt_path)\n",
        "\n",
        "# 5. test_acc - reload the best model\n",
        "best_model = models.resnet18()\n",
        "num_ftrs = best_model.fc.in_features\n",
        "best_model.fc = torch.nn.Linear(num_ftrs, 2)  # Assuming binary classification: Hot Dog or Not\n",
        "best_model.load_state_dict(torch.load(model_path))\n",
        "best_model.to(device)\n",
        "\n",
        "test_acc, _ = evaluate(best_model, test_loader, device, criterion)\n",
        "print(f\"Test Accuracy: {test_acc:.2f}%, according model saved to {model_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show_wrong_predictions_limited(model, loader, classes, device, num_wrong=10):\n",
        "    import matplotlib.pyplot as plt\n",
        "    import torch\n",
        "    import torch.nn.functional as F\n",
        "    import math\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    wrong_images = []\n",
        "    wrong_labels = []\n",
        "    wrong_preds = []\n",
        "    wrong_probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            probs = F.softmax(outputs, dim=1)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            # 找到错误分类\n",
        "            mask = preds != labels\n",
        "            if mask.any():\n",
        "                wrong_images.append(images[mask])\n",
        "                wrong_labels.append(labels[mask])\n",
        "                wrong_preds.append(preds[mask])\n",
        "                wrong_probs.append(probs[mask])\n",
        "\n",
        "            # 检查是否已经收集够 num_wrong 个\n",
        "            total_wrong = sum([x.size(0) for x in wrong_images])\n",
        "            if total_wrong >= num_wrong:\n",
        "                break\n",
        "\n",
        "    if len(wrong_images) == 0:\n",
        "        print(\"没有错误预测的样本！\")\n",
        "        return\n",
        "\n",
        "    # 合并 batch 并只保留前 num_wrong 个\n",
        "    wrong_images = torch.cat(wrong_images)[:num_wrong]\n",
        "    wrong_labels = torch.cat(wrong_labels)[:num_wrong]\n",
        "    wrong_preds = torch.cat(wrong_preds)[:num_wrong]\n",
        "    wrong_probs = torch.cat(wrong_probs)[:num_wrong]\n",
        "\n",
        "    # 可视化：多行，每行最多5张\n",
        "    num_cols = 5\n",
        "    num_rows = math.ceil(len(wrong_images) / num_cols)\n",
        "    fig = plt.figure(figsize=(num_cols * 4, num_rows * 4))  # 调整 figsize 适应行列\n",
        "\n",
        "    for i in range(len(wrong_images)):\n",
        "        row = i // num_cols\n",
        "        col = i % num_cols\n",
        "        ax = fig.add_subplot(num_rows, num_cols, i+1, xticks=[], yticks=[])\n",
        "        ax.imshow(wrong_images[i].permute(1, 2, 0).cpu().numpy())\n",
        "        pred_class = classes[wrong_preds[i]]\n",
        "        true_class = classes[wrong_labels[i]]\n",
        "        pred_prob = wrong_probs[i][wrong_preds[i]].item()*100\n",
        "        ax.set_title(f\"Predicted: {pred_class}\\nActual: {true_class}\\nprob: {pred_prob:.1f}%\", fontsize=10, color='red')\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "Q0z19bFbG8w9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "fuy2cLfS82Ig"
      },
      "outputs": [],
      "source": [
        "model_path = model_save_path+'/best_resnet18_model-b4-fc.pth' # This is the best one\n",
        "model = models.resnet18()\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = torch.nn.Linear(num_ftrs, 2)  # Assuming binary classification: Hot Dog or Not\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "classes = list(testset.name_to_label.keys())\n",
        "# print(classes)\n",
        "show_wrong_predictions_limited(model, test_loader, classes, device, num_wrong=10)\n",
        "# show_result_random(model, test_loader, classes, device, num_images=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JutwebMr8z7G"
      },
      "source": [
        "# saliency map analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3AZr44_3uKx"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7c547_S_4bs"
      },
      "outputs": [],
      "source": [
        "# Load the fine-tuned ResNet-18 model\n",
        "model_path = model_save_path+'/best_resnet18_model-b4-fc.pth' # This is the best one\n",
        "model = models.resnet18()\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = torch.nn.Linear(num_ftrs, 2)  # Assuming binary classification: Hot Dog or Not\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "\n",
        "#  preprocess = test_transform\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize((128,128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "# 'hot dog' class is index 0, non-hot-dog is index of 1\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "def get_saliency_map(img_path):\n",
        "    img_pil = Image.open(img_path).convert(\"RGB\")\n",
        "    input_tensor = preprocess(img_pil).unsqueeze(0).to(device)\n",
        "    input_tensor.requires_grad_()\n",
        "\n",
        "    # Forward pass\n",
        "    output = model(input_tensor)\n",
        "    score = output[0, 0] #the second index of 0 represents hotdog\n",
        "\n",
        "    # Backward pass\n",
        "    model.zero_grad()\n",
        "    score.backward()\n",
        "\n",
        "    # Get the saliency map\n",
        "    saliency, _ = torch.max(input_tensor.grad.data.abs(), dim=1)\n",
        "    saliency = saliency.squeeze().cpu().numpy()\n",
        "\n",
        "    # Normalize saliency\n",
        "    saliency = (saliency - saliency.min()) / (saliency.max() - saliency.min())\n",
        "\n",
        "    # Convert original image to numpy\n",
        "    img = np.array(img_pil)\n",
        "\n",
        "    # Resize saliency to match image size\n",
        "    saliency_resized = np.array(Image.fromarray(saliency).resize((img.shape[1], img.shape[0])))\n",
        "\n",
        "    # Create overlay\n",
        "    overlay = np.uint8(plt.cm.jet(saliency_resized) * 255)\n",
        "    overlay = overlay[..., :3]\n",
        "    overlay = np.float32(overlay) / 255\n",
        "\n",
        "    # Blend original and saliency map\n",
        "    blended = np.clip(overlay * 0.5 + np.float32(img) / 255 * 0.5, 0, 1)\n",
        "\n",
        "    # Display in a row\n",
        "    plt.figure(figsize=(7,2))\n",
        "\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.title(\"Original Image\")\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.title(\"Saliency Map\")\n",
        "    plt.imshow(saliency_resized, cmap='hot')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1,3,3)\n",
        "    plt.title(\"Overlay\")\n",
        "    plt.imshow(blended)\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "img_paths = [\n",
        "    # data_path+\"/test/nothotdog/\"+\"pets (683).jpg\",\n",
        "    # data_path+\"/test/nothotdog/\"+\"pets (682).jpg\",\n",
        "    # data_path+\"/test/nothotdog/\"+\"pets (679).jpg\",\n",
        "    # data_path+\"/test/nothotdog/\"+\"pets (677).jpg\",\n",
        "    data_path+\"/test/hotdog/\"+\"hotdog (344).jpg\",\n",
        "    data_path+\"/test/hotdog/\"+\"hotdog (343).jpg\",\n",
        "    data_path+\"/test/hotdog/\"+\"hotdog (342).jpg\",\n",
        "    data_path+\"/test/hotdog/\"+\"hotdog (341).jpg\",\n",
        "]\n",
        "\n",
        "for img_path in img_paths:\n",
        "  get_saliency_map(img_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = model_save_path+'/best_resnet18_model-b4-fc.pth' # This is the best one\n",
        "model = models.resnet18()\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = torch.nn.Linear(num_ftrs, 2)  # Assuming binary classification: Hot Dog or Not\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "preprocess = test_transform\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize((128,128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "img_path = data_path+\"/test/hotdog/\"+\"hotdog (344).jpg\" # Removed the trailing comma\n",
        "img_pil = Image.open(img_path).convert(\"RGB\")\n",
        "input_tensor = preprocess(img_pil).unsqueeze(0).to(device)\n",
        "input_tensor.requires_grad_()\n",
        "\n",
        "output = model(input_tensor)\n",
        "print('***'*20 + 'output' + \"***\"*20)\n",
        "print(output)\n",
        "\n",
        "score = output[0, 0]\n",
        "print('***'*20 + 'score' + \"***\"*20)\n",
        "print(score)"
      ],
      "metadata": {
        "id": "3gQsDscoEMy5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "pITKeJC1fx0Y"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}